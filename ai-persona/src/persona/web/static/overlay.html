<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Persona Overlay</title>

    <!-- Import map for Three.js and TalkingHead -->
    <script type="importmap">
      {
        "imports": {
          "three": "https://cdn.jsdelivr.net/npm/three@0.170.0/build/three.module.js",
          "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.170.0/examples/jsm/",
          "talkinghead": "https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.7/modules/talkinghead.mjs"
        }
      }
    </script>

    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        background: transparent;
        display: flex;
        justify-content: center;
        align-items: center;
        min-height: 100vh;
        font-family:
          -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
        overflow: hidden;
      }

      .avatar-container {
        display: flex;
        flex-direction: column;
        align-items: center;
        gap: 12px;
      }

      #avatar-canvas {
        width: 400px;
        height: 400px;
        border-radius: 12px;
      }

      .emotion-label {
        color: white;
        font-size: 14px;
        font-weight: 600;
        text-transform: uppercase;
        letter-spacing: 1px;
        background: rgba(0, 0, 0, 0.5);
        padding: 4px 12px;
        border-radius: 12px;
        opacity: 0.8;
      }

      .status {
        position: fixed;
        bottom: 10px;
        right: 10px;
        font-size: 10px;
        color: rgba(255, 255, 255, 0.5);
      }

      .status.connected {
        color: #22c55e;
      }

      .status.disconnected {
        color: #ef4444;
      }

      .status.loading {
        color: #fbbf24;
      }

      /* Fallback emoji avatar (shown while 3D loads) */
      .avatar-fallback {
        width: 150px;
        height: 150px;
        border-radius: 50%;
        background: #6b7280;
        display: flex;
        justify-content: center;
        align-items: center;
        font-size: 60px;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
      }

      .avatar-fallback.hidden {
        display: none;
      }

      #avatar-canvas.hidden {
        display: none;
      }
    </style>
  </head>
  <body>
    <div class="avatar-container">
      <!-- Fallback emoji while 3D avatar loads -->
      <div id="avatar-fallback" class="avatar-fallback">üòê</div>
      <!-- 3D Avatar canvas container -->
      <div id="avatar-canvas" class="hidden"></div>
      <div id="emotion-label" class="emotion-label">neutral</div>
    </div>
    <div id="status" class="status disconnected">disconnected</div>

    <script type="module">
      import { TalkingHead } from "talkinghead";

      // DOM Elements
      const avatarCanvas = document.getElementById("avatar-canvas");
      const avatarFallback = document.getElementById("avatar-fallback");
      const emotionLabel = document.getElementById("emotion-label");
      const statusEl = document.getElementById("status");

      // TalkingHead instance
      let head = null;
      let headReady = false;

      // WebSocket state
      let ws = null;
      let reconnectAttempts = 0;
      const maxReconnectAttempts = 10;

      // Emotion to emoji/gesture mapping for TalkingHead
      const emotionMap = {
        neutral: { mood: "neutral", emoji: "üòê" },
        happy: { mood: "happy", emoji: "üòä" },
        excited: { mood: "happy", emoji: "ü§©" },
        surprised: { mood: "surprised", emoji: "üòÆ" },
        thinking: { mood: "neutral", emoji: "ü§î" },
        laughing: { mood: "happy", emoji: "üòÇ" },
        sad: { mood: "sad", emoji: "üò¢" },
        angry: { mood: "angry", emoji: "üò†" },
        confused: { mood: "neutral", emoji: "üòï" },
      };

      // Current state
      let currentEmotion = "neutral";
      let isSpeaking = false;

      /**
       * Initialize the TalkingHead 3D avatar
       */
      async function initTalkingHead() {
        statusEl.textContent = "loading avatar...";
        statusEl.className = "status loading";

        try {
          console.log("Creating TalkingHead instance...");

          // Create TalkingHead instance
          head = new TalkingHead(avatarCanvas, {
            ttsEndpoint: null, // We'll handle TTS separately
            lipsyncModules: ["en"],
            cameraView: "head", // Focus on head/face
            cameraDistance: 0.6,
            cameraX: 0,
            cameraY: 0,
            cameraRotateX: 0,
            cameraRotateY: 0,
            cameraPanX: 0,
            cameraPanY: 0,
            lightAmbientColor: 0xffffff,
            lightAmbientIntensity: 1.2,
            lightDirectColor: 0xffffff,
            lightDirectIntensity: 0.8,
            lightDirectPhi: 1.0,
            lightDirectTheta: 2.0,
            lightSpotIntensity: 0,
            avatarMood: "neutral",
            // Don't set modelRoot when using custom GLB URLs
          });

          console.log("Loading avatar GLB...");

          // Try loading local avatar first, fall back to Ready Player Me if it fails
          let avatarUrl = `${window.location.origin}/static/avatar.glb`;
          let avatarLoaded = false;

          try {
            console.log("Attempting local avatar:", avatarUrl);
            await head.showAvatar({
              url: avatarUrl,
              body: "F",
              avatarMood: "neutral",
              lipsyncLang: "en",
            });
            avatarLoaded = true;
            console.log("Local avatar loaded successfully");
          } catch (localError) {
            console.warn("Local avatar failed:", localError.message);
            console.log(
              "Falling back to Ready Player Me avatar (valid until Jan 31, 2026)...",
            );

            // Fallback to Ready Player Me avatar with proper morph targets
            avatarUrl =
              "https://models.readyplayer.me/64bfa15f0e72c63d7c3934a6.glb?morphTargets=ARKit,Oculus+Visemes,mouthOpen,mouthSmile,eyesClosed,eyesLookUp,eyesLookDown&lod=0";

            try {
              await head.showAvatar({
                url: avatarUrl,
                body: "F",
                avatarMood: "neutral",
                lipsyncLang: "en",
              });
              avatarLoaded = true;
              console.log("Ready Player Me fallback avatar loaded");
            } catch (fallbackError) {
              throw new Error(
                `Both local and fallback avatars failed: ${fallbackError.message}`,
              );
            }
          }

          if (avatarLoaded) {
            // Avatar loaded successfully
            headReady = true;
            avatarFallback.classList.add("hidden");
            avatarCanvas.classList.remove("hidden");

            console.log("TalkingHead avatar loaded successfully");

            // Apply current emotion if any
            if (currentEmotion) {
              await setEmotion(currentEmotion);
            }
          }
        } catch (error) {
          console.error("Failed to load TalkingHead avatar:", error);
          console.error("Error details:", error.message, error.stack);
          // Keep fallback visible
          statusEl.textContent = "using emoji fallback";
          statusEl.className = "status connected";
        }
      }

      /**
       * Connect to WebSocket server
       */
      function connect() {
        const protocol = window.location.protocol === "https:" ? "wss:" : "ws:";
        const wsUrl = `${protocol}//${window.location.host}/ws`;

        ws = new WebSocket(wsUrl);

        ws.onopen = () => {
          console.log("WebSocket connected");
          statusEl.textContent = "connected";
          statusEl.className = "status connected";
          reconnectAttempts = 0;
        };

        ws.onclose = () => {
          console.log("WebSocket disconnected");
          statusEl.textContent = "disconnected";
          statusEl.className = "status disconnected";

          // Attempt reconnect
          if (reconnectAttempts < maxReconnectAttempts) {
            reconnectAttempts++;
            const delay = Math.min(
              1000 * Math.pow(2, reconnectAttempts),
              30000,
            );
            console.log(`Reconnecting in ${delay}ms...`);
            setTimeout(connect, delay);
          }
        };

        ws.onerror = (error) => {
          console.error("WebSocket error:", error);
        };

        ws.onmessage = (event) => {
          try {
            const data = JSON.parse(event.data);
            handleMessage(data);
          } catch (e) {
            console.error("Failed to parse message:", e);
          }
        };
      }

      /**
       * Handle incoming WebSocket messages
       */
      async function handleMessage(data) {
        console.log("Received:", data);

        switch (data.type) {
          case "init":
            await setEmotion(data.emotion || "neutral");
            setSpeaking(data.speaking || false);
            break;

          case "emotion":
            await setEmotion(data.value);
            break;

          case "speaking":
            setSpeaking(data.value);
            break;

          case "speak":
            // Handle text-to-speech with lip sync
            if (data.text && headReady) {
              await speakText(data.text, data.options);
            }
            break;

          case "audio":
            // Handle audio playback with lip sync
            if (data.url && headReady) {
              await playAudioWithLipSync(data.url, data.visemes);
            }
            break;
        }
      }

      /**
       * Set the avatar's emotion/mood
       */
      async function setEmotion(emotion) {
        currentEmotion = emotion;
        const mapping = emotionMap[emotion] || emotionMap["neutral"];

        // Update label
        emotionLabel.textContent = emotion;

        // Always update fallback emoji (for when 3D doesn't load)
        avatarFallback.textContent = mapping.emoji;

        if (headReady && head) {
          try {
            // Set the mood for idle behavior
            head.setMood(mapping.mood);

            // Play the emoji gesture for immediate expression
            head.playGesture(mapping.emoji, 2.0);

            console.log(
              `Emotion set to: ${emotion} (mood: ${mapping.mood}, gesture: ${mapping.emoji})`,
            );
          } catch (error) {
            console.error("Failed to set emotion:", error);
          }
        }
      }

      /**
       * Set speaking state (visual indicator)
       */
      function setSpeaking(speaking) {
        isSpeaking = speaking;

        if (headReady && head) {
          // TalkingHead handles speaking animation automatically during speech
          // This is just for state tracking
          console.log(`Speaking state: ${speaking}`);
        }
      }

      /**
       * Speak text using TalkingHead's built-in TTS
       */
      async function speakText(text, options = {}) {
        if (!headReady || !head) return;

        try {
          await head.speakText(text, {
            ttsLang: options.lang || "en-US",
            ttsVoice: options.voice || "en-US-Wavenet-F",
            ttsRate: options.rate || 1.0,
            ttsPitch: options.pitch || 1.0,
            ttsVolume: options.volume || 1.0,
            lipsyncLang: "en",
            ...options,
          });
        } catch (error) {
          console.error("Failed to speak text:", error);
        }
      }

      /**
       * Play audio file with lip sync
       */
      async function playAudioWithLipSync(audioUrl, visemes = null) {
        if (!headReady || !head) return;

        try {
          await head.speakAudio({
            audio: audioUrl,
            lipsyncLang: "en",
          });
        } catch (error) {
          console.error("Failed to play audio:", error);
        }
      }

      /**
       * Start audio streaming session (for real-time TTS)
       */
      function startAudioStream(sampleRate = 22050) {
        if (!headReady || !head) return;

        head.streamStart(
          {
            sampleRate: sampleRate,
            lipsyncLang: "en",
          },
          () => {
            console.log("Audio stream started");
          },
          () => {
            console.log("Audio stream ended");
          },
        );
      }

      /**
       * Feed audio chunk to stream
       */
      function feedAudioChunk(audioData, visemes, vtimes, vdurations) {
        if (!headReady || !head) return;

        head.streamAudio({
          audio: audioData,
          visemes: visemes,
          vtimes: vtimes,
          vdurations: vdurations,
        });
      }

      /**
       * Stop audio stream
       */
      function stopAudioStream() {
        if (!headReady || !head) return;
        head.streamStop();
      }

      // Initialize on page load
      async function init() {
        // Start loading the 3D avatar
        initTalkingHead();

        // Connect to WebSocket
        connect();
      }

      // Start initialization
      init();

      // Expose functions for debugging
      window.talkingHead = {
        head: () => head,
        setEmotion,
        speakText,
        playAudioWithLipSync,
        startAudioStream,
        feedAudioChunk,
        stopAudioStream,
      };
    </script>
  </body>
</html>
